{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfXivWzwWD8y"
      },
      "source": [
        "# Trabajo práctico 2\n",
        "**Algebra Lineal computacional, 2do cuatrimestre 2023, Universidad de Buenos Aires**\n",
        "\n",
        "Tobias Llop, LU 871/22\n",
        "\n",
        "Felipe Pasquet, LU 1084/22\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUDG5UWTYFb0"
      },
      "source": [
        "## Ejercicio 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CipeQBIHYJ83"
      },
      "source": [
        "### a) importamos los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u7NJ-Zc8YCkB"
      },
      "outputs": [],
      "source": [
        "#Importamos librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "F5NqvvwnYZqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5675d1f2-1bf2-4b9b-9c7a-29c50dbd26c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Importamos los datos\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/wine.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzWOtezWY6mD"
      },
      "source": [
        "### b) separamos nuestros datos en las variables dependientes (X) e independientes (Y)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DduF0TrpZDXc"
      },
      "outputs": [],
      "source": [
        "y = data['Customer_Segment']\n",
        "X = data.drop(columns='Customer_Segment')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOoVmvMh1hm7"
      },
      "source": [
        "### c) Normalización\n",
        "Como nuestros datos tienen variables de distinta naturaleza, que se miden de distintas maneras y con distintas escalas, normalizaremos nuestros datos para que un atributo no tenga mayor importancia en nuestra predicción final simplemente por la escala en la que estaba medido. Normalizar los datos, hace que todos estén alrededor del 0 y podamos ver la varianza real de ellos.\n",
        "A continuación normalizaremos nuestras variables dependientes $x_i$, para ello diseñamos distintas funciones que se basan en las siguientes fórmulas mátematicas:\n",
        "\n",
        "$ s = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^{N} (X_i - \\overline{X})^2}$\n",
        "\n",
        "$\\overline{X} = \\frac{1}{N} \\sum_{i=1}^{N} X_i$\n",
        "\n",
        "$x_i = \\frac{X_i - \\overline{X}}{s}$\n",
        "\n",
        "donde $s$ es el desvío estandar, implementado en nuestra funcíon *desvio*, $\\overline{X}$ es el promedio de cada variable dependiente y está implementado en nuestra función  *promedio*. Por último la función $x_i$ es la fórmula que normaliza y centra nuestras variables y está implementada en la función *normalizar*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "am0ltQc11l-_"
      },
      "outputs": [],
      "source": [
        "# creamos funciones para calcular el promedio y la desviacion estandar\n",
        "def promedio(x):\n",
        "    res = 0\n",
        "    for i in x:\n",
        "        res += i\n",
        "    return res/len(x)\n",
        "\n",
        "def desviacion(x):\n",
        "    res = 0\n",
        "    for i in x:\n",
        "        res += (i-promedio(x))**2\n",
        "    return np.sqrt(res/(len(x)-1))\n",
        "\n",
        "def normalizar(x):\n",
        "    return (x-promedio(x))/desviacion(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRwbDW8i5ll1"
      },
      "source": [
        "A continuación utilizaremos las funciones anteriores y normalizaremos nuestras variables dependientes. Este paso es importante ya que a la hora de comparar nuestras variables deben estar escaladas, sino aquellas variables cuya escala sea mayor dominarán al resto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nGK0yv1J54Gh"
      },
      "outputs": [],
      "source": [
        "var_dependientes_normalizados = X.copy()\n",
        "def normalizar_df(df):\n",
        "    promed = []\n",
        "    desviac = []\n",
        "    for x in df.columns:\n",
        "        promed.append(promedio(df[x]))\n",
        "        desviac.append(desviacion(df[x]))\n",
        "        df[x] = normalizar(df[x])\n",
        "    return df, promed, desviac\n",
        "var_dependientes_normalizados, prom, desv = normalizar_df(var_dependientes_normalizados)\n",
        "var_dependientes_normalizados_mat = var_dependientes_normalizados.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-stlrZDd8D2k"
      },
      "source": [
        "### d) Matriz de covarianza\n",
        "El siguiente paso que realizaremos con nuestras variables dependientes será calcular su matriz de covarianza. La matriz de covarianza es una matriz cuadrada que contiene la covarianza entre los elementos de un vector. En este caso contendrá la covarianza entre nuestras 13 variables dependientes y será de dimensión $13\\times13$.\n",
        "\n",
        "Esta matriz cumple distintas propiedades:\n",
        "1. Es simétrica\n",
        "2. Los elementos de la diagonal principal de la matriz de covarianza representan las varianzas de las variables individuales\n",
        "3. Los elementos fuera de la diagonal principal representan las covarianzas entre las diferentes variables. Un valor positivo indica una relación positiva, un valor negativo indica una relación negativa, y un valor cercano a cero indica una relación débil o nula entre las variables.\n",
        "\n",
        "Calcularemos la matriz de covarianza utilizando la función predefinida *numpy.cov()* de la biblioteca numpy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EpicA3c-9LHS"
      },
      "outputs": [],
      "source": [
        "def covarianza(data):\n",
        "    num_variables = len(data[0])\n",
        "    num_observaciones = len(data)\n",
        "\n",
        "    # Calculamos la media de cada variable\n",
        "    means = [sum(variable) / num_observaciones for variable in zip(*data)]\n",
        "\n",
        "    # Inicializamos la matriz de covarianza con ceros\n",
        "    res = np.zeros((num_variables,num_variables))\n",
        "\n",
        "    # Calculamos los términos de la matriz de covarianza\n",
        "    for i in range(num_variables):\n",
        "        for j in range(num_variables):\n",
        "            res[i][j] = sum((data[k][i] - means[i]) * (data[k][j] - means[j]) for k in range(num_observaciones)) / (num_observaciones - 1)\n",
        "    return res\n",
        "\n",
        "# Calculamos la matriz de covarianza\n",
        "matriz_covarianza = covarianza(var_dependientes_normalizados_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApPh5ZNS-Cwz"
      },
      "source": [
        "### e) Método de la potencia\n",
        "Nuestro siguiente objetivo es encontrar el máximo de los autovalores, y su correspondiente autovector, de la matriz de covarianza hallada en el item anterior.\n",
        "\n",
        "Para ello utilizaremos el conocido **método de la potencia**.\n",
        "\n",
        "Diseñamos la  función `metodo_potencia` que toma como entrada la matriz $A$ y un vector inicial $v_0$.  Definimos criterio para detener las iteraciones del método a la iteración en la que la diferencia absoluta entre dos valores propios sucesivos sea menor que $1 \\times 10^{-8}$.\n",
        "\n",
        "La función devuelve el valor propio dominante `r_actual` como el máximo autovalor $\\lambda$ y a su autovector asociado correspondiente $v$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNG8BUUG-FbA",
        "outputId": "2ec9be0b-bda9-467a-d8e6-f09a73ea6a8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Autovector: [ 0.14435538 -0.24517549 -0.00203407 -0.23932097  0.14200814  0.39466434\n",
            "  0.42293412 -0.29853155  0.3134316  -0.08858823  0.29669956  0.37615857\n",
            "  0.28677183]\n",
            "Autovalor máximo: 4.70585025119514\n"
          ]
        }
      ],
      "source": [
        "def metodo_potencia(A, x0):\n",
        "    x = x0\n",
        "    r_ant = 0\n",
        "    while True:\n",
        "        x_nuevo = (A @ x) / np.linalg.norm(A @ x) #Multiplicamos A por x y normalizamos\n",
        "        r_actual = x_nuevo @ A @ x_nuevo # Calculamos el autovalor actual\n",
        "        if np.abs(r_actual - r_ant) < 1e-8:\n",
        "            break\n",
        "        x = x_nuevo\n",
        "        r_ant = r_actual\n",
        "    return x, r_actual\n",
        "\n",
        "#Definimos un vector random de R^13 para inicializar el método de la potencia.\n",
        "x0 = np.random.rand(13)\n",
        "\n",
        "#Ejecutamos el metodo de la potencia para nuestra matriz de covarianza\n",
        "autovector, autovalor = metodo_potencia(matriz_covarianza, x0)\n",
        "print(\"Autovector:\", autovector)\n",
        "print(\"Autovalor máximo:\", autovalor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts7DhoO_FiBx"
      },
      "source": [
        "### f) n maximos (Preguntar por lo ultimo)\n",
        "A continuación hallaremos no solo el autovalor máximo y su correspondiente autovector, sino que ampliaremos el método de la potencia para que calcule sus $n$ autovalores máximos y autovectores correspondientes sucesivos.\n",
        "\n",
        "Para ello, definimos nuestra función `n_maximos` que toma como valores de entrada a la matriz de covarianza, un vector de $ℝ^{13}$ para inicializar el método de la potencia y un entero $n$ que indica los $n$ autovalores y autovectores máximos que querramos. Luego devuelve dos listas, una con los autovalores y otra con los autovectores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HJ2zQ2PNEpo0"
      },
      "outputs": [],
      "source": [
        "def n_maximos(A, x0, n):\n",
        "    autovalores = []\n",
        "    autovectores = []\n",
        "    for i in range(n):\n",
        "      x, r_actual = metodo_potencia(A,x0)\n",
        "      # Guardamos el aval y avec maximo\n",
        "      autovalores.append(r_actual)\n",
        "      autovectores.append(x)\n",
        "      # Deflacionamos la matriz A\n",
        "      A = A - r_actual * np.outer(x, x)\n",
        "    return autovalores, autovectores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx20niSaHYwA"
      },
      "source": [
        "La cantidad de autovalores de nuestra matriz de covarianza es la misma que la cantidad de propiedades de los vinos.\n",
        "\n",
        "Cada autovector de la matriz de covarianza son distintas direcciones en las que se mueven nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBPspQvzO30t"
      },
      "source": [
        "### g) Clasificación\n",
        "\n",
        "La idea del siguiente punto es que, dado un conjunto de características de un vino en particular, obtener su clasificación, es decir, a qué segmento de cliente pertenece. Para ello utilizaremos la función `clasificarVino`, que recibe un vector de $1\\times 13$ asociado a las caracteristicas de un vino, una matriz $W$ de componentes principales de nuestros datos y un número $k$ asociado a la cantidad de vecinos más cercanos con la que queremos realizar el algoritmo knn. La función va a devolver un número dentro del intervalo [1,2,3] asociado a la clasificación del segmento de cliente al que pertenecen las características del vino particular.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rbTdB6LO6N9",
        "outputId": "b5ed9798-ed3e-4d91-f435-c1dd20d84269"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.0\n"
          ]
        }
      ],
      "source": [
        "#Busco las 13 componentes principales\n",
        "x0 = np.random.rand(13)\n",
        "autovalores, autovectores = n_maximos(matriz_covarianza,x0,13)\n",
        "\n",
        "#Ponemos a cada componente principal como columna de nustra matriz W\n",
        "def armar_W(n, avecs):\n",
        "  W = np.zeros((13,n))\n",
        "  for i in range(13):\n",
        "      for j in range(n):\n",
        "          v = avecs[j]\n",
        "          W[i][j] = v[i]\n",
        "  return W\n",
        "#Armamos nuestra matriz con 13 componentes principales\n",
        "W = armar_W(13, autovectores)\n",
        "def distancia(v1,v2):\n",
        "  return np.linalg.norm(v1 - v2)\n",
        "\n",
        "def clasificarVino(x,W,k,data,clas):\n",
        "  #x es el vino que queremos clasificar\n",
        "  #W son las componentes principales que utilizaremos\n",
        "  #k es la cantidad de vecinos\n",
        "  #data es el dataset con el que vamos a entrenar nuestro modelo\n",
        "  #clas es la clasificacion de nuestra data\n",
        "\n",
        "  T = data@W #Proyectamos todos los datos sobre nuestras componentes principales\n",
        "  vino = x@W #Proyectamos los datos de las caracteristicas del nuevo vino sobre nuestras componentes principales\n",
        "  distancias = [] #Inicializamos una lista donde guardaremos todas las distancias euclideas\n",
        "  ap_1 = 0\n",
        "  ap_2 = 0\n",
        "  ap_3 = 0\n",
        "  res = 0\n",
        "  for i in range(len(T)):\n",
        "      #Guardamos las distancias y la posición en la que se encontraba en nuestros datos\n",
        "      distancias.append((distancia(T[i], vino), clas[i])) #posicion(data[i], var_dependientes_normalizados_mat)))\n",
        "  #Ordenamos las distancias para que primero se encuentren las más cercanas\n",
        "  distancias.sort(key=lambda distancias: distancias[0])\n",
        "\n",
        "  #Contamos apariciones\n",
        "  for i in range(k):\n",
        "\n",
        "    if distancias[i][1] == 1.0:\n",
        "      ap_1 += 1\n",
        "    elif distancias[i][1] == 2.0:\n",
        "      ap_2 += 1\n",
        "    elif distancias[i][1] == 3.0:\n",
        "      ap_3 += 1\n",
        "  #Vemos quien tiene más apariciones\n",
        "  if ap_3 >= ap_2 and ap_3 >= ap_1:\n",
        "      res = 3.0\n",
        "  elif ap_2 >= ap_3 and ap_2 >= ap_1:\n",
        "      res = 2.0\n",
        "  elif ap_1 >= ap_2 and ap_1 >= ap_3:\n",
        "      res = 1.0\n",
        "  #Devolvemos la clase mas representada entre los k vecinos\n",
        "  return res\n",
        "\n",
        "#Ejemplo\n",
        "\n",
        "#x = np.array([13.0, 1.72, 2.13, 11.0, 109, 2.70, 3.06, 0.32, 2.40, 8.0, 1.04, 3.90, 1185])\n",
        "x = np.array([13.17,\t2.59,\t2.37,\t20.0,\t120,\t1.65,\t0.68,\t0.53,\t1.46,\t9.30,\t0.60,\t1.62,\t840])  #debería dar 3\n",
        "#Normalizo los datos de mi vino\n",
        "df = X.copy()\n",
        "df, pr, desv = normalizar_df(df)\n",
        "\n",
        "xn = (x-pr)/desv\n",
        "#knn con 1 vecino\n",
        "df = df.to_numpy()\n",
        "print(clasificarVino(xn,W, 1, df, y.to_numpy()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdgOYmfjNizI"
      },
      "source": [
        "## Ejercicio 2\n",
        "Primero dividimos nuestros datos en entrenamiento y testeo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wRlPhHgxeiie"
      },
      "outputs": [],
      "source": [
        "#dividimos nuestro dataset en Train (80%) y test (20%)\n",
        "train, test = train_test_split(data, test_size=0.2)\n",
        "\n",
        "ytrain = train['Customer_Segment']\n",
        "ytest = test['Customer_Segment']\n",
        "ytrain = ytrain.to_numpy()\n",
        "ytest = ytest.to_numpy()\n",
        "train = train.drop(columns='Customer_Segment')\n",
        "test = test.drop(columns='Customer_Segment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "j3vEfOk5yFpo"
      },
      "outputs": [],
      "source": [
        "#normalizamos nuestros datos (con nuestro train set)\n",
        "\n",
        "train, pr, desv = normalizar_df(train)\n",
        "\n",
        "test = (test-pr)/desv\n",
        "train = train.to_numpy()\n",
        "test = test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAkFILZPTQGx"
      },
      "source": [
        "### a) Varianza explicada\n",
        "Para la siguiente consigna calculamos la varianza explicada de cada autovalor de nuestra matriz de covarianza. A continuación se puede ver una tabla donde se resumen los resultados:\n",
        "\n",
        "<table>\n",
        "  <thead>\n",
        "    <tr>\n",
        "      <th>Modelo PCA</th>\n",
        "      <th>Componente</th>\n",
        "      <th>Varianza explicada</th>\n",
        "      <th>Porcentaje</th>\n",
        "      <th>Acumulado</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <td>1 componente principal</td>\n",
        "      <td>1</td>\n",
        "      <td>0.35</td>\n",
        "      <td>35%</td>\n",
        "      <td>35%</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <td>2 componentes principales</td>\n",
        "      <td>1</td>\n",
        "      <td>0.35</td>\n",
        "      <td>35%</td>\n",
        "      <td>35%</td>\n",
        "    </tr>\n",
        "      <tr>\n",
        "      <td>2 componentes principales</td>\n",
        "      <td>2</td>\n",
        "      <td>0.20</td>\n",
        "      <td>20%</td>\n",
        "      <td>55%</td>\n",
        "    </tr>\n",
        "        <tr>\n",
        "      <td>3 componentes principales</td>\n",
        "      <td>1</td>\n",
        "      <td>0.35</td>\n",
        "      <td>35%</td>\n",
        "      <td>35%</td>\n",
        "    </tr>\n",
        "      <tr>\n",
        "      <td>3 componentes principales</td>\n",
        "      <td>2</td>\n",
        "      <td>0.20</td>\n",
        "      <td>35%</td>\n",
        "      <td>55%</td>\n",
        "    </tr>\n",
        "        </tr>\n",
        "      <tr>\n",
        "      <td>3 componentes principales</td>\n",
        "      <td>3</td>\n",
        "      <td>0.11</td>\n",
        "      <td>11%</td>\n",
        "      <td>66%</td>\n",
        "    </tr>\n",
        "            <tr>\n",
        "      <td>3 componentes principales</td>\n",
        "      <td>1</td>\n",
        "      <td>0.35</td>\n",
        "      <td>35%</td>\n",
        "      <td>35%</td>\n",
        "    </tr>\n",
        "      <tr>\n",
        "      <td>3 componentes principales</td>\n",
        "      <td>2</td>\n",
        "      <td>0.20</td>\n",
        "      <td>35%</td>\n",
        "      <td>55%</td>\n",
        "    </tr>\n",
        "        </tr>\n",
        "      <tr>\n",
        "      <td>3 componentes principales</td>\n",
        "      <td>3</td>\n",
        "      <td>0.11</td>\n",
        "      <td>11%</td>\n",
        "      <td>66%</td>\n",
        "    </tr>\n",
        "      <tr>\n",
        "      <td>4 componentes principales</td>\n",
        "      <td>4</td>\n",
        "      <td>0.07</td>\n",
        "      <td>7%</td>\n",
        "      <td>73%</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z2c1C_ATnRZ",
        "outputId": "9122ea32-15e3-48fe-ffa3-62c17dd65460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.36330248257898445, 0.19739140420538281, 0.1088059013872567, 0.06953206058216801, 0.057180408910828616, 0.05158612735278239, 0.0437815579208133, 0.029166980839510054, 0.020931506897416005, 0.018752544216427195, 0.0171761295197695, 0.01364066903222066, 0.008752226556440344]\n"
          ]
        }
      ],
      "source": [
        "matriz_covarianza_train = covarianza(train)\n",
        "#Calculamos la varianza explicada para cada autovalor de nuestra matriz W de autovectores.\n",
        "x0 = np.random.rand(13)\n",
        "autovalores_t, autovectores_t = n_maximos(matriz_covarianza_train,x0,13)\n",
        "varianza_explicada = [autovalor / np.sum(autovalores_t) for autovalor in autovalores_t]\n",
        "print(varianza_explicada)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBsFmnIrd96F"
      },
      "source": [
        "### b) Comparación de modelos\n",
        "Para evaluar la performance de nuestros modelos, decidimos utilizar como medida la Accuracy, para ello definimos la funcion accuracy que calcula la cantidad de aciertos de nuestro modelo sobre el total de muestras en el conjunto de test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kE0On_bUku7w",
        "outputId": "3d5a99f3-f990-41f4-d6ad-e2b0979c6bd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9166666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#Armo mi matriz W con 2 componentes\n",
        "W = armar_W(2, autovectores_t)\n",
        "\n",
        "#Funcion de accuracy.\n",
        "def accuracy(test, train,ytest, ytrain, W, k):\n",
        "  le_pego = 0 #Aciertos\n",
        "  no_le_pego = 0 #Desaciertos\n",
        "  for i in range(len(test)):\n",
        "    if clasificarVino(test[i],W, k, train, ytrain) == ytest[i]: #Usamos KNN con k vecinos\n",
        "      le_pego +=1\n",
        "    else:\n",
        "      no_le_pego += 1\n",
        "  res = le_pego / (no_le_pego + le_pego)\n",
        "  return res\n",
        "accuracy(test, train, ytest, ytrain, W, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzdhhyeVJIOG"
      },
      "source": [
        "Luego, decidimos comparar valores de accuracy para distintas cantidades de componentes en nuestra matriz $W$. Para ello guardamos los datos de 20 modelos con 1,2,3 y 4 componentes en una matriz y promediamos los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QB6agNUmoDzg"
      },
      "outputs": [],
      "source": [
        "#Creamos una matriz donde almacenaremos las accuracy para distintos modelos y componentes\n",
        "matriz_acu = np.zeros((20,4))\n",
        "i = 0\n",
        "x0 = np.random.rand(13)\n",
        "while i < 20:\n",
        "  #me genero un nuevo test y train set\n",
        "  train, test = train_test_split(data, test_size=0.2)\n",
        "  ytrain = train['Customer_Segment']\n",
        "  ytest = test['Customer_Segment']\n",
        "  ytrain = ytrain.to_numpy()\n",
        "  ytest = ytest.to_numpy()\n",
        "  train = train.drop(columns='Customer_Segment')\n",
        "  test = test.drop(columns='Customer_Segment')\n",
        "  # normalizo mis datos\n",
        "  train, pr, desv = normalizar_df(train)\n",
        "  test = (test-pr)/desv\n",
        "  train = train.to_numpy()\n",
        "  test = test.to_numpy()\n",
        "\n",
        "  matriz_covarianza_train = covarianza(train)\n",
        "  autovalores_t2, autovectores_t2 = n_maximos(matriz_covarianza_train,x0,4)\n",
        "  for j in range(4):\n",
        "    W = armar_W(j, autovectores_t2)\n",
        "    matriz_acu[i][j] = accuracy(test, train, ytest, ytrain, W, 1)\n",
        "  i +=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9u-2ZAyuSfi",
        "outputId": "066ae409-ff4c-42b3-f314-be3cb16e0809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.3402777777777778, 0.7694444444444445, 0.9513888888888886, 0.9361111111111111]\n"
          ]
        }
      ],
      "source": [
        "promedios = []\n",
        "for j in range(4):\n",
        "    suma = 0\n",
        "    for i in range(20):\n",
        "        suma += matriz_acu[i][j]\n",
        "    promedios.append(suma/matriz_acu.shape[0])\n",
        "print(promedios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7VuiOmT3si2U",
        "outputId": "9a58633c-1c2d-47d2-aa86-2f1cc378e6a7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Graficamos\n",
        "plt.plot([1,2,3,4],promedios)\n",
        "plt.title('Promedio de la Accuracy de 20 modelos')\n",
        "plt.xlabel('componentes')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eN4neXIX6TmH"
      },
      "source": [
        "En el gráfico, Vemos que efectivamente, sucede lo que suponiamos. Usar dos o tres componentes presenta una mejora frente a usar una sola, pero a partir de la cuarta componente, el rendimiento/efectividad de nuestros modelos empieza a bajar.\n",
        "\n",
        "A continuación veremos con cuantas componentes nuestro modelo es más eficiente y presenta menor complejidad a la hora de clasificar, para finalmente tomar una decisión"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxuP77iM8J5K",
        "outputId": "eabc3284-b318-4e74-f237-95e1bf0daa47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La función con 1 componentes tardó 0.1380302906036377 segundos en ejecutarse.\n",
            "La función con 2 componentes tardó 0.12602901458740234 segundos en ejecutarse.\n",
            "La función con 3 componentes tardó 0.14603304862976074 segundos en ejecutarse.\n",
            "La función con 4 componentes tardó 0.127028226852417 segundos en ejecutarse.\n"
          ]
        }
      ],
      "source": [
        "#Buscamos las comp. principales\n",
        "x0 = np.random.rand(13)\n",
        "autovalores, autovectores = n_maximos(matriz_covarianza,x0,13)\n",
        "#Ejemplo vino\n",
        "\n",
        "for i in range(1,5):\n",
        "  inicio = time.time()\n",
        "  W = armar_W(i, autovectores) #armo matriz de componentes principales\n",
        "  for x in test: #clasifico todo mi dataset (train + test)\n",
        "    clasificarVino(x,W,5,train, ytrain)\n",
        "  for x in train:\n",
        "    clasificarVino(x,W,5,train, ytrain)\n",
        "  fin = time.time()\n",
        "  # Cálculo del tiempo transcurrido\n",
        "  tiempo_transcurrido = fin - inicio\n",
        "  print(f\"La función con {i} componentes tardó {tiempo_transcurrido} segundos en ejecutarse.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECf_tYOZAdz7"
      },
      "source": [
        "Viendo que la complejidad de la función `clasificarVino` aumenta con el número de componentes, ya que al proyectar las matrices $W$ de mayor dimensión y recorrerlas la complejidad aumenta y considerando que la varianza acumulada del modelo con 2 componentes es de 55%. Tomamos la decisión de que la mejor opción para clasificar vinos es el modelo con 2 componentes, ya que tiene una accuracy similar a los modelos de 3 y 4 componentes, es más eficiente y es un indicador que toma en cuenta como varían mas de la mitad de nuestros datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tikm7Nj50MQP"
      },
      "source": [
        "### c) Matriz de confusión\n",
        "una matriz de confusión, es una matriz de dos dimensiones, la cual\n",
        "tiene en una de sus direcciones los valores de testeo verdaderos y en la otra dirección los valores estimados.\n",
        "\n",
        "Para esta ocasión decidimos comparar entre dos categorias de vinos la 1 y la 2. En la dirección (arriba-abajo) se encuentran los valores de testeo reales y en la dirección (izquierda-derecha) se encuentran los valores predichos por el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td_6XjnIzB2i",
        "outputId": "cd896a88-93f1-4bb9-8852-44f419ae57aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de confusion: \n",
            " [[12.  1.]\n",
            " [ 0. 14.]]\n"
          ]
        }
      ],
      "source": [
        "avals_t, avecs_t =  n_maximos(covarianza(train),x0,13) #Obtenemos los autovectores\n",
        "W = armar_W(2, avecs_t) #Creamos nuestra matriz W\n",
        "#Matriz de confusion.\n",
        "def confusion(test, train,ytest, ytrain, W):\n",
        "  res = np.zeros((2,2))\n",
        "  for i in range(len(test)):\n",
        "    if clasificarVino(test[i],W, 3, train, ytrain) == ytest[i] and ytest[i] == 1: #Era 1 y clasifico bien\n",
        "      res[0][0] += 1\n",
        "    elif clasificarVino(test[i],W, 3, train, ytrain) == ytest[i] and ytest[i] == 2: #Era 2 y clasifico bien\n",
        "      res[1][1] += 1\n",
        "    elif clasificarVino(test[i],W, 3, train, ytrain) != ytest[i] and ytest[i] == 1: #Era 1 y el modelo clasifico mal\n",
        "      res[0][1] += 1\n",
        "    elif clasificarVino(test[i],W, 3, train, ytrain) != ytest[i] and ytest[i] == 2: #Era 2 y el modelo clasifico bien\n",
        "      res[1][0] += 1\n",
        "  return res\n",
        "print(\"Matriz de confusion: \\n\",confusion(test, train,ytest, ytrain, W))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1pKiTnaHLpW"
      },
      "source": [
        "Observando la matriz de confusión podemos ver que nuestro modelo KNN, es bastante bueno clasificando a nuestros datos porque tuvo una baja cantidad de desaciertos. Por lo que confirmamos que la decisión de quedarnos con la matriz de 2 componentes fue la adecuada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3i1WhJcgGV7"
      },
      "source": [
        "## Conclusiones Finales\n",
        "Finalizado el proceso de normalización de nuestros datos, modelado y evaluación de nuestros modelos, llegamos a las siguientes conclusiones:\n",
        "\n",
        "* Es importante normalizar nuestros datos poque si las unidades de medida en diferentes atributos son distintas, los atributos con magnitudes mayores pueden dominar la variabilidad y tener un impacto desproporcionado en los componentes principales. La normalización asegura que todas los atributos tengan una escala comparable.\n",
        "\n",
        "* La reduccion en componentes principales de nuestros datos mejora la eficiencia de nuestros modelos predictivos, y es util para clasificar nuevos vinos de una forma mas eficiente y rápida.\n",
        "* El modelo con 2 componentes acumula más de la mitad de la varianza acumulada de nuestros datos con un 55%. Mientras que el modelo de 3 componentes aumenta tan solo un 11% más la varianza acumulada con respecto al modelo de dos componentes, alcanzando un 66%.\n",
        "* La performance de nuestro modelo KNN no es buena para el modelo con 1 sola componente, y tiende a disminuir a partir de la cuarta componente.\n",
        "* El mejor modelo para clasificar vinos con una accuracy aceptable y de forma rápida es el modelo con 2 componentes."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}